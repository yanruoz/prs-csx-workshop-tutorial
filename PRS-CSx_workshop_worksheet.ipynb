{
 "cells": [
  {
   "cell_type": "raw",
   "id": "91182647",
   "metadata": {},
   "source": [
    "This Jupyter Notebook is the worksheet version of the PRS-CSx workshop tutorial. It has code blocks removed to encourage trainees to type along with the lecture version by their sides."
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ba0780f",
   "metadata": {},
   "source": [
    "Overall flow:\n",
    "1. Run PRS-CSx\n",
    "2. Matrices preparation\n",
    "3. Run regression to find weight parameters a_hat and b_hat (y = a_hat * X @ Weas + b_hat * X @ Weur)\n",
    "4. Predict phenotype on validation and test dataset\n",
    "5. Plot true values against predicted values\n",
    "6. Evaluate using deviance-based R^2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "931f3466",
   "metadata": {},
   "source": [
    "Disclaimer:\n",
    "    This is just one way of coding. Please feel free to experiment on your self, and you're welcome to share if you find ways of coding more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feaa97d-703c-4337-8d43-925e0ee86719",
   "metadata": {},
   "source": [
    "### 0. Set up Python virtual environments with Snellius' JupyterHub"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3b88751-f8d4-4492-9107-e18ea7dba706",
   "metadata": {},
   "source": [
    "# Create a working directory\n",
    "# When you log in, you should be at your root directory. It's recommended that you create a folder as your working directory.\n",
    "mkdir working_dir_name\n",
    "\n",
    "# Copy Jupyter Notebooks to working directory\n",
    "cp /projects/0/pgsr0673/scur0497/PRS-CSx_workshop_lecture path_to_working_dir\n",
    "cp /projects/0/pgsr0673/scur0497/PRS-CSx_workshop_worksheet path_to_working_dir"
   ]
  },
  {
   "cell_type": "raw",
   "id": "06565e10-2f19-400b-9c6d-017bef16c7cf",
   "metadata": {},
   "source": [
    "# Load Python module used by the https://jupyter.snellius.surf.nl/2021 JupyterHub\n",
    "module load 2021\n",
    "module load JupyterHub/1.4.1-GCCcore-10.3.0\n",
    " \n",
    "# Create and activate virtual environment\n",
    "virtualenv my_env\n",
    " \n",
    "# Purge modules so that any subsequent pip-installs don't pick up on python packages from the module environment\n",
    "module purge\n",
    " \n",
    "# Activate virtual environment\n",
    "source my_env/bin/activate\n",
    "  \n",
    "# Install ipykernel in the virtual environment\n",
    "pip install ipykernel\n",
    "\n",
    "# Install any other packages needed in the virtual environment\n",
    "pip install pandas\n",
    "pip install numpy\n",
    "pip install matplotlib\n",
    "pip install scikit-learn\n",
    "\n",
    "# Load some other useful modules\n",
    "module load 2022 #you must load this before loading subsequent modules \n",
    "module load Python/3.10.4-GCCcore-11.3.0 \n",
    "module load SciPy-bundle/2022.05-intel-2022a\n",
    "module load h5py/3.7.0-foss-2022a\n",
    "  \n",
    "# Install the virtual environment as custom kernel. It will show up in the Jupyter Notebook Server with the name passed to the '--name' argument.\n",
    "python -m ipykernel install --user --name=my_env\n",
    " \n",
    "# Makes sure the kernel only uses Python packages from the conda environment, not from the module environment\n",
    "sed -i '/\"-m\",/i \\ \\ \"-E\",' ~/.local/share/jupyter/kernels/my_env/kernel.json\n",
    "\n",
    "# Go to the JupyterHub: https://jupyter.snellius.surf.nl/2022 & Have it open for later use\n",
    "# Choose my_env as the kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a852cd",
   "metadata": {},
   "source": [
    "### 1. Run PRS-CSx"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ac73d578-62aa-42d9-91a9-ab4c4e63fb48",
   "metadata": {},
   "source": [
    "Following the PRS-CSx pipeline, we have 1) cloned git repository 2) downloaded Python and dependencies 3) downloaded the reference panels (EUR & EAS) and the SNP information. Now, let's use PRS-CSx on the test dataset!\n",
    "\n",
    "Back to terminal!\n",
    "\n",
    "# Start an interactive node\n",
    "srun -n 1 -t 1:00:00 --pty /bin/bash\n",
    "\n",
    "* Allocation will probably take 1-3 min\n",
    "\n",
    "# Create an output directory\n",
    "mkdir output_dir_name\n",
    "# \"cd\" there and use \"pwd\" to find that directory -- it will be your path_to_output\n",
    "\n",
    "# Use PRS-CSx\n",
    "python path_to_script/PRScsx.py --ref_dir=path_to_ref --bim_prefix=path_to_bim/test --sst_file=path_to_sumstats/EUR_sumstats.txt,path_to_sumstats/EAS_sumstats.txt --n_gwas=200000,100000 --pop=EUR,EAS --chrom=22 --phi=1e-2 --out_dir=path_to_output --out_name=test\n",
    "\n",
    "Example:\n",
    "path_to_script = /projects/0/pgsr0673/scur0497/PRScsx\n",
    "path_to_ref = /projects/0/pgsr0673/scur0497/ref\n",
    "path_to_bim = /projects/0/pgsr0673/scur0497/PRScsx/test_data\n",
    "path_to_sumstats = /projects/0/pgsr0673/scur0497/PRScsx/test_data\n",
    "path_to_output = put down your output path!\n",
    "\n",
    "*path_to_output is the only place you need to change\n",
    "\n",
    "python /projects/0/pgsr0673/scur0497/PRScsx/PRScsx.py --ref_dir=/projects/0/pgsr0673/scur0497/ref --bim_prefix=/projects/0/pgsr0673/scur0497/PRScsx/test_data/test --sst_file=/projects/0/pgsr0673/scur0497/PRScsx/test_data/EUR_sumstats.txt,/projects/0/pgsr0673/scur0497/PRScsx/test_data/EAS_sumstats.txt --n_gwas=200000,100000 --pop=EUR,EAS --chrom=22 --phi=1e-2 --out_dir=/home/scur0497/test/test_output --out_name=test\n",
    "\n",
    "*The test data analysis would be finished in approximately 1 min when using 8Gb of RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c04f72",
   "metadata": {},
   "source": [
    "### 2. Matrices Preperation\n",
    "### 2.1 Prepare the weight matrices W_eas & W_eur"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2bbb660-b02e-4752-b2bc-72a5bf56b260",
   "metadata": {},
   "source": [
    "# Cut the PRS output files using command line to keep only the rsid and the effect size\n",
    "General instruction: awk '{print $2 \"\\t\" $6}' inputfile.txt > outputfile.txt\n",
    "Specific instructions:\n",
    "cd to your output directory, then put down one line at a time\n",
    "awk '{print $2 \"\\t\" $6}' test_EAS_pst_eff_a1_b0.5_phi1e-02_chr22.txt > EAS_var_w.txt\n",
    "awk '{print $2 \"\\t\" $6}' test_EUR_pst_eff_a1_b0.5_phi1e-02_chr22.txt > EUR_var_w.txt"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b3b9b92-386d-4060-b96f-0b2f15e87a0c",
   "metadata": {},
   "source": [
    "Now open Jupyter Notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18c35a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60d39aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these paths to your own paths\n",
    "path_EAS_var_w = '/home/scur0497/test/test_output/EAS_var_w.txt'\n",
    "path_EUR_var_w = '/home/scur0497/test/test_output/EUR_var_w.txt'\n",
    "\n",
    "# Read in the files and put them in dictionaries\n",
    "EAS_var_w = pd.read_csv(path_EAS_var_w, sep = '\\t', header = None) # read the file in as a panda dataframe; sep = '\\t' --> deliminator is a tab character\n",
    "EUR_var_w = pd.read_csv(path_EUR_var_w, sep = '\\t', header = None)\n",
    "EAS_dic = dict(zip(EAS_var_w[0], EAS_var_w[1])) # zip function: pairs each entry from column 0 with the corresponding entry in column 1 in the EAS_var_w dataframe\n",
    "EUR_dic = dict(zip(EAS_var_w[0], EAS_var_w[1]))\n",
    "\n",
    "# Find overlapping rsid variants and create a new dictionary with these variants and a tuple of values from both dictionaries\n",
    "overlap_var = set(EAS_dic.keys()).intersection(set(EUR_dic.keys())) # convert keys (variants) from both dictionaries into sets; intersection method: identifies overlapping keys between two sets\n",
    "overlap_var_list = list(overlap_var) # convert the set of overlapping keys into a list for later use\n",
    "combined_dict = {key: (EAS_dic[key], EUR_dic[key]) for key in overlap_var} # create a new dictionary; keys = overlapping variants; values = tuple containing the corresponding weight values for that variant from EAS_dic and EUR_dic; *tuple = immutable data type that stores multiple items into one variable\n",
    "\n",
    "\n",
    "# Write the overlapping variants to a txt file\n",
    "\n",
    "# Change this path to your own path\n",
    "path_overlap_risk_variants = '/home/scur0497/test/test_output/overlap_risk_variants.txt'\n",
    "\n",
    "with open(path_overlap_risk_variants, 'w') as f: # open a file in the specified path for writing mode; context manaer 'with' --> ensure the file is properly closed after writing\n",
    "    for key in overlap_var: # iterate through the set of overlapping variants\n",
    "        f.write(f\"{key}\\n\") # write out each variant followed by a new line character \"\\n\" --> each variant written on a new line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5491975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the variant weights matrices\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.10f' % x) # display floating point numbers up to 10 decimal places; ensures that the numbers are shown with full precision\n",
    "\n",
    "# W_eas\n",
    "\n",
    "\n",
    "# W_eur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73522e26",
   "metadata": {},
   "source": [
    "### 2.2 Prepare the genotype matrix X and phenotype matrix y in validation and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16a4e048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.         0.         0.         ... 0.         1.         0.04249645]\n",
      " [2.         0.         1.         ... 0.         0.         0.08080722]\n",
      " [1.         0.         2.         ... 1.         2.         0.06038308]\n",
      " ...\n",
      " [0.         0.         1.         ... 0.         1.         0.03393009]\n",
      " [1.         0.         2.         ... 0.         0.         0.04689794]\n",
      " [1.         0.         2.         ... 0.         1.         0.03195786]]\n",
      "(504, 902)\n"
     ]
    }
   ],
   "source": [
    "# This path is same for everyone\n",
    "path_data = \"/projects/0/pgsr0673/scur0497/genotype_phenotype_1kgEAS.txt\"\n",
    "\n",
    "# Read in the file that has genotype and phenotype for each individual\n",
    "\n",
    "\n",
    "# The file is prepared such that it has 504 rows (individuals) x 902 columns (variants + effect sizes); entries: first 901 columns: allele count for each variant; last column = effect size of that variant from PRS-CSx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c797d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate genotype and phenotype information\n",
    "\n",
    "# print the matrices and their shapes for inspection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "860c7f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into validation and test datasets\n",
    "\n",
    "\n",
    "# set a random seed for reproducibility\n",
    "\n",
    "\n",
    "# specify the proportion of data to be used for validation\n",
    "\n",
    "\n",
    "# calculate the number of samples based on the proportion\n",
    "\n",
    "\n",
    "# set the validation indices\n",
    "\n",
    "\n",
    "# set the test indices\n",
    "\n",
    "\n",
    "# Extract the rows according to the indices for geno, phen, vali, and test respectively\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345b7676",
   "metadata": {},
   "source": [
    "### 3. Run regression to find weight parameters a_hat and b_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea92a142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the model input\n",
    "\n",
    "# based on the equation y = a_hat * X @ Weas + b_hat * X @ Weur, calculate the weighted input data for the EAS population\n",
    "\n",
    "# horizontally stack the weighted inputs for both population for model input\n",
    "XW_vali = np.hstack((XWeas_vali, XWeur_vali)) \n",
    "\n",
    "# In essence, this block of code takes the validation data, \n",
    "# multiplies it by population-specific weight matrices, \n",
    "# and then concatenates the results side by side to form a combined input for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c710920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "151c7a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_hat =0.9337471644122599\n",
      "b_hat =-0.08808776795046623\n"
     ]
    }
   ],
   "source": [
    "# Obtain the regression parameters\n",
    "a_hat = model.coef_[0]\n",
    "b_hat = model.coef_[1]\n",
    "print(f\"{a_hat =}\")\n",
    "print(f\"{b_hat =}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276b5ffc",
   "metadata": {},
   "source": [
    "### 4. Predict phenotype on validation and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad8cb44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 1)\n",
      "(201,)\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on validation data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "550cd83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the prediction on test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964a027a",
   "metadata": {},
   "source": [
    "### 5. Plot true values against predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b8719a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a blank canvas 10 in. wide x 5 inch. tall\n",
    "\n",
    "\n",
    "# Compute global minimum and maximum for x and y axes for setting the x & y ranges\n",
    "min_true = min(min(y_vali), min(y_test))\n",
    "max_true = max(max(y_vali), max(y_test))\n",
    "min_pred = min(min(y_hat_vali), min(y_hat))\n",
    "max_pred = max(max(y_hat_vali), max(y_hat))\n",
    "\n",
    "# For the validation cohort\n",
    "plt.subplot(1, 2, 1) # (# rows, # columns, index of this plot)\n",
    "plt.scatter(y_vali, y_hat_vali, alpha = 0.5) # alpha sets the transparency of the dot markers\n",
    "plt.title('Validation Dataset')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.plot([min_true, max_true], [min_pred, max_pred], 'k', linestyle='dashed') # draw a line that shows perfect correlation between true and predicted values\n",
    "\n",
    "# For the test cohort\n",
    "\n",
    "\n",
    "# Save the figure & inspect it!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea814ddf",
   "metadata": {},
   "source": [
    "### 6. Evaluate using deviance-based R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef99d64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the deviance based on the y_hat for the test data (= residual deviance = total squared difference between the true output values and the predicted output values)\n",
    "\n",
    "\n",
    "# Print the deviance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36047996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deviance_null = 0.19363495614719278\n"
     ]
    }
   ],
   "source": [
    "# Calculate null deviance = total squared difference between the true output values and their mean\n",
    "\n",
    "\n",
    "# Print the null deviance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e4c55da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate deviance-based R2\n",
    "\n",
    "# Print the R2\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
